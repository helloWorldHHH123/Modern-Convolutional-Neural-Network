"""
ä½œè€…ï¼šcy
æ—¶é—´ï¼š2025-11-05
å†…å®¹ï¼š7.1 æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆAlexNetï¼‰
å¯¹æ¯”ï¼šLeNetåœ¨å°æ•°æ®é›†ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œä½†æ˜¯åœ¨æ›´å¤§ã€æ›´çœŸå®çš„æ•°æ®é›†ä¸Šè®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œçš„æ€§èƒ½å’Œå¯è¡Œæ€§è¿˜æœ‰å¾…ç ”ç©¶ã€‚
AlexNetå’ŒLeNetçš„è®¾è®¡ç†å¿µéå¸¸ç›¸ä¼¼ï¼Œä½†ä¹Ÿå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼š
1. AlexNetæ¯”ç›¸å¯¹è¾ƒå°çš„LeNet5è¦æ·±å¾—å¤šã€‚AlexNetç”±å…«å±‚ç»„æˆï¼šäº”ä¸ªå·ç§¯å±‚ã€ä¸¤ä¸ªå…¨è¿æ¥éšè—å±‚å’Œä¸€ä¸ª
å…¨è¿æ¥è¾“å‡ºå±‚ã€‚
2. AlexNetä½¿ç”¨ReLUè€Œä¸æ˜¯sigmoidä½œä¸ºå…¶æ¿€æ´»å‡½æ•°ã€‚
3. ä¸ºäº†è¿›ä¸€æ­¥æ‰©å……æ•°æ®ï¼ŒAlexNetåœ¨è®­ç»ƒæ—¶å¢åŠ äº†å¤§é‡çš„å›¾åƒå¢å¼ºæ•°æ®ï¼Œå¦‚ç¿»è½¬ã€è£åˆ‡å’Œå˜è‰²ã€‚è¿™ä½¿å¾—æ¨¡å‹æ›´å¥å£®ï¼Œæ›´å¤§çš„æ ·æœ¬é‡
æœ‰æ•ˆåœ°å‡å°‘äº†è¿‡æ‹Ÿåˆã€‚

èƒŒæ™¯ï¼š
2012å¹´ï¼ŒAlexNetæ¨ªç©ºå‡ºä¸–ã€‚å®ƒé¦–æ¬¡è¯æ˜äº†å­¦ä¹ åˆ°çš„ç‰¹å¾å¯ä»¥è¶…è¶Šæ‰‹å·¥è®¾è®¡çš„ç‰¹å¾ã€‚
Alex Krizhevskyã€Ilya Sutskeverå’ŒGeoff Hintonæå‡ºäº†ä¸€ç§æ–°çš„å·ç§¯ç¥ç»ç½‘ç»œå˜ä½“AlexNetã€‚
åœ¨2012å¹´ImageNetæŒ‘æˆ˜èµ›ä¸­å–å¾—äº†è½°åŠ¨ä¸€æ—¶çš„æˆç»©ã€‚
åœ¨ç½‘ç»œçš„æœ€åº•å±‚ï¼Œæ¨¡å‹å­¦ä¹ åˆ°äº†ä¸€äº›ç±»ä¼¼äºä¼ ç»Ÿæ»¤æ³¢å™¨çš„ç‰¹å¾æŠ½å–å™¨ã€‚

æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œçš„çªç ´å‡ºç°åœ¨2012å¹´ã€‚çªç ´å¯å½’å› äºä¸¤ä¸ªå…³é”®å› ç´ ã€‚
1.ç¼ºå°‘çš„æˆåˆ†ï¼šæ•°æ®
åŒ…å«è®¸å¤šç‰¹å¾çš„æ·±åº¦æ¨¡å‹éœ€è¦å¤§é‡çš„æœ‰æ ‡ç­¾æ•°æ®ï¼Œæ‰èƒ½æ˜¾è‘—ä¼˜äºåŸºäºå‡¸ä¼˜åŒ–çš„ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚çº¿æ€§æ–¹æ³•å’Œæ ¸æ–¹æ³•ï¼‰ã€‚
2009å¹´ï¼ŒImageNetæ•°æ®é›†å‘å¸ƒï¼Œå¹¶å‘èµ·ImageNetæŒ‘æˆ˜èµ›ï¼šè¦æ±‚ç ”ç©¶äººå‘˜ä»100ä¸‡ä¸ªæ ·æœ¬ä¸­è®­ç»ƒæ¨¡å‹ï¼Œä»¥åŒºåˆ†1000ä¸ªä¸åŒ
ç±»åˆ«çš„å¯¹è±¡ã€‚ImageNetæ•°æ®é›†ç”±æ–¯å¦ç¦æ•™æˆæé£é£å°ç»„çš„ç ”ç©¶äººå‘˜å¼€å‘ï¼Œåˆ©ç”¨è°·æ­Œå›¾åƒæœç´¢ï¼ˆGoogle Image
Searchï¼‰å¯¹æ¯ä¸€ç±»å›¾åƒè¿›è¡Œé¢„ç­›é€‰ï¼Œå¹¶åˆ©ç”¨äºšé©¬é€Šä¼—åŒ…ï¼ˆAmazon Mechanical Turkï¼‰æ¥æ ‡æ³¨æ¯å¼ å›¾ç‰‡çš„ç›¸å…³
ç±»åˆ«ã€‚è¿™ç§è§„æ¨¡æ˜¯å‰æ‰€æœªæœ‰çš„ã€‚è¿™é¡¹è¢«ç§°ä¸ºImageNetçš„æŒ‘æˆ˜èµ›æ¨åŠ¨äº†è®¡ç®—æœºè§†è§‰å’Œæœºå™¨å­¦ä¹ ç ”ç©¶çš„å‘å±•ï¼ŒæŒ‘
æˆ˜ç ”ç©¶äººå‘˜ç¡®å®šå“ªäº›æ¨¡å‹èƒ½å¤Ÿåœ¨æ›´å¤§çš„æ•°æ®è§„æ¨¡ä¸‹è¡¨ç°æœ€å¥½ã€‚
2.ç¼ºå°‘çš„æˆåˆ†ï¼šç¡¬ä»¶
å½“Alex Krizhevskyå’ŒIlya Sutskeverå®ç°äº†å¯ä»¥åœ¨GPUç¡¬ä»¶ä¸Šè¿è¡Œçš„æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œæ—¶ï¼Œ
ä¸€ä¸ªé‡å¤§çªç ´å‡ºç°äº†ã€‚ä»–ä»¬æ„è¯†åˆ°å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„è®¡ç®—ç“¶é¢ˆï¼šå·ç§¯å’ŒçŸ©é˜µä¹˜æ³•ï¼Œéƒ½æ˜¯å¯ä»¥åœ¨ç¡¬ä»¶ä¸Šå¹¶è¡ŒåŒ–çš„æ“ä½œã€‚
äºæ˜¯ï¼Œä»–ä»¬ä½¿ç”¨ä¸¤ä¸ªæ˜¾å­˜ä¸º3GBçš„NVIDIA GTX580 GPUå®ç°äº†å¿«é€Ÿå·ç§¯è¿ç®—ã€‚ä»–ä»¬çš„åˆ›æ–°cudaâ€convnet89
å‡ å¹´æ¥å®ƒä¸€ç›´æ˜¯è¡Œä¸šæ ‡å‡†ï¼Œå¹¶æ¨åŠ¨äº†æ·±åº¦å­¦ä¹ çƒ­æ½®ã€‚
"""

import torch
from torch import nn
import torchvision
from torchvision import transforms
from torch.utils import data
import time
import numpy as np
import matplotlib.pyplot as plt

net = nn.Sequential(
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ª11*11çš„æ›´å¤§çª—å£æ¥æ•æ‰å¯¹è±¡ã€‚
    # åŒæ—¶ï¼Œæ­¥å¹…ä¸º4ï¼Œä»¥å‡å°‘è¾“å‡ºçš„é«˜åº¦å’Œå®½åº¦ã€‚
    # å¦å¤–ï¼Œè¾“å‡ºé€šé“çš„æ•°ç›®è¿œå¤§äºLeNet
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # ä½¿ç”¨ä¸‰ä¸ªè¿ç»­çš„å·ç§¯å±‚å’Œè¾ƒå°çš„å·ç§¯çª—å£ã€‚
    # é™¤äº†æœ€åçš„å·ç§¯å±‚ï¼Œè¾“å‡ºé€šé“çš„æ•°é‡è¿›ä¸€æ­¥å¢åŠ ã€‚
    # åœ¨å‰ä¸¤ä¸ªå·ç§¯å±‚ä¹‹åï¼Œæ±‡èšå±‚ä¸ç”¨äºå‡å°‘è¾“å…¥çš„é«˜åº¦å’Œå®½åº¦
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    # è¿™é‡Œï¼Œå…¨è¿æ¥å±‚çš„è¾“å‡ºæ•°é‡æ˜¯LeNetä¸­çš„å¥½å‡ å€ã€‚ä½¿ç”¨dropoutå±‚æ¥å‡è½»è¿‡æ‹Ÿåˆ
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    # æœ€åæ˜¯è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000
    nn.Linear(4096, 10))


# 7.1.3 è¯»å–æ•°æ®é›†
# å°½ç®¡åŸæ–‡ä¸­AlexNetæ˜¯åœ¨ImageNetä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œä½†æœ¬ä¹¦åœ¨è¿™é‡Œä½¿ç”¨çš„æ˜¯Fashionâ€MNISTæ•°æ®é›†ã€‚
# å› ä¸ºå³ä½¿åœ¨ç°ä»£GPUä¸Šï¼Œè®­ç»ƒImageNetæ¨¡å‹ï¼ŒåŒæ—¶ä½¿å…¶æ”¶æ•›å¯èƒ½éœ€è¦æ•°å°æ—¶æˆ–æ•°å¤©çš„æ—¶é—´ã€‚
# å°†AlexNetç›´æ¥åº”ç”¨äºFashionâ€MNISTçš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œ
# Fashionâ€MNISTå›¾åƒçš„åˆ†è¾¨ç‡ï¼ˆ28 Ã— 28åƒç´ ï¼‰ä½äºImageNetå›¾åƒã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ
# æˆ‘ä»¬å°†å®ƒä»¬å¢åŠ åˆ°224 Ã— 224ï¼ˆé€šå¸¸æ¥è®²è¿™ä¸æ˜¯ä¸€ä¸ªæ˜æ™ºçš„åšæ³•ï¼Œä½†åœ¨è¿™é‡Œè¿™æ ·åšæ˜¯ä¸ºäº†æœ‰æ•ˆä½¿ç”¨AlexNetæ¶æ„ï¼‰

# è¿”å›ä¸€ä¸ªæ‰¹é‡batch_sizeçš„æ•°æ®ï¼ˆè®­ç»ƒ+æµ‹è¯•ï¼‰
def load_data_fashion_mnist(batch_size,resize=None):
    # å›¾åƒå¤„ç†é¡ºåºå¾ˆé‡è¦ï¼šå…ˆè°ƒæ•´å¤§å°ï¼Œå†è½¬æ¢ä¸ºå¼ é‡
    # trans å˜é‡æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªå›¾åƒé¢„å¤„ç†çš„æ“ä½œåºåˆ—ï¼ˆæµæ°´çº¿æˆ–åˆ—è¡¨ï¼‰
    trans = [transforms.ToTensor()]  # 1. åˆ›å»ºåŸºç¡€åˆ—è¡¨
    print("type(trans) = ", type(trans))
    if resize:      # 2. æ¡ä»¶æ·»åŠ resize
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)     # 3. ç»„åˆæµæ°´çº¿
    mnist_train = torchvision.datasets.FashionMNIST(root="./data",train=True,transform=trans,download=True)
    mnist_test = torchvision.datasets.FashionMNIST(root="./data",train=False,transform=trans,download=True)
    return data.DataLoader(mnist_train,batch_size,shuffle=True), data.DataLoader(mnist_test,batch_size,shuffle=False)

# 7.1.4 è®­ç»ƒAlexNet

class Timer:
    def __init__(self):
        self.times = []
        self.start()
    def start(self):
        """å¯åŠ¨è®¡æ—¶å™¨"""
        self.tik = time.time()
    def stop(self):
        """åœæ­¢è®¡æ—¶å™¨å¹¶å°†æ—¶é—´è®°å½•åœ¨åˆ—è¡¨ä¸­"""
        self.times.append(time.time()-self.tik)
        return self.times[-1]
    def sum(self):
        """è¿”å›æ—¶é—´æ€»å’Œ"""
        return sum(self.times)
    def cumsum(self):
        """è¿”å›ç´¯è®¡æ—¶é—´"""
        """
        np.array(self.times) - å°†åˆ—è¡¨è½¬æ¢ä¸ºNumPyæ•°ç»„
        .cumsum() - è®¡ç®—ç´¯ç§¯å’Œ
        .tolist() - è½¬æ¢å›Pythonåˆ—è¡¨
        """
        return np.array(self.times).cumsum().tolist()

def accruacy(y_hat,y):
    # è€ƒè™‘å¤šåˆ†ç±»æƒ…å†µï¼Œæ­¤æ—¶éœ€è¦å–æ¦‚ç‡æœ€å¤§å€¼
    if len(y_hat.shape)>1 and y_hat.shape[1]>1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype)==y
    return float(cmp.type(y.dtype).sum())

def evaluate_accuracy_gpu(net,test_iter,device = None):
    # è¿”å›æµ‹è¯•ç²¾åº¦
    if isinstance(net, nn.Module):
        net.eval()   # è®¾ç½®è¯„ä¼°æ¨¡å¼ï¼Œè¿™é‡Œä¼šå–æ¶ˆåå‘ä¼ æ’­
        if not device:  # å¦‚æœdeviceä¸ºNoneæ—¶æ‰§è¡Œï¼Œè¿™é‡Œçš„ç›®çš„æ˜¯è®¾ç½®cpuè¿˜æ˜¯cuda
            print('device',device)
            # è‡ªåŠ¨è®¾ç½®ç½‘ç»œå‚æ•°æ‰€åœ¨çš„deviceï¼Œå³ cuda: 0
            device = next(iter(net.parameters())).device
            # device = net(iter(net.parameters())).device
            print('net device',device)
        # [é¢„æµ‹æ­£ç¡®ä¸ªæ•°ï¼Œæ€»æµ‹è¯•æ ·æœ¬ä¸ªæ•°]
        metric = [0.0] * 2
        with torch.no_grad():
            for X,y in test_iter:
                # é¦–å…ˆç§»åŠ¨æ•°æ®åˆ°éœ€è¦çš„è®¾å¤‡ä¸Š
                if isinstance(X,list):
                    # å°†å¤šä¸ªå¼ é‡ç§»è‡³deviceä¸Š
                    X = [x.to(device) for x in X]
                else:
                    X = X.to(device)
                y = y.to(device)
                metric = [a + float(b) for a,b in zip(metric,[accruacy(net(X),y),y.numel()])]
        # ä¸€ä¸ªæ‰¹é‡çš„æ•°æ®çš„æµ‹è¯•ç²¾åº¦ç´¯è®¡å®Œä¹‹å
        return metric[0] / metric[1]

def plot_training_curves(train_losses, train_accuracies, test_accuracies, num_epochs):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    epochs = range(1, num_epochs + 1)

    # åˆ›å»ºå­å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # ç»˜åˆ¶å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(epochs, train_accuracies, 'r-', label='Training Accuracy', linewidth=2)
    ax2.plot(epochs, test_accuracies, 'g--', label='Test Accuracy', linewidth=2)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.set_title('Training and Test Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

def train_ch7(net,train_iter,test_iter,num_epochs,lr,device):
    # åˆå§‹åŒ–æƒé‡
    def init_weight(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)
    net.apply(init_weight)
    print('training on', device)
    net.to(device)
    optimizer = torch.optim.SGD(net.parameters(),lr=lr)
    loss = nn.CrossEntropyLoss()
    timer, num_batches = Timer(), len(train_iter)
    # æ·»åŠ ï¼šç”¨äºå­˜å‚¨å†å²æ•°æ®çš„åˆ—è¡¨
    train_losses = []
    train_accuracies = []
    test_accuracies = []
    for epoch in range(num_epochs):
        metric = [0.0] * 3
        for i, (X,y) in enumerate(train_iter):
            timer.start()
            optimizer.zero_grad()
            X,y = X.to(device), y.to(device)
            y_hat = net(X)
            l = loss(y_hat,y)
            l.backward()
            optimizer.step()
            with torch.no_grad():
                metric = [a+float(b) for a,b in zip(metric,[l*X.shape[0],accruacy(y_hat,y),X.shape[0]])]
            timer.stop()
            # å½“å‰æ‰¹æ¬¡æ•°æ®çš„å¹³å‡è®­ç»ƒæŸå¤±ã€å¹³å‡è®­ç»ƒç²¾åº¦
            train_loss = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
        # ä¸€ä¸ªæ‰¹é‡æ•°æ®ç»“æŸä¹‹åè¿›è¡Œæµ‹è¯•
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        train_losses.append(train_loss)
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        # æ‰“å°å½“å‰epochçš„è®­ç»ƒç²¾åº¦å’Œæµ‹è¯•ç²¾åº¦
        print(f'epoch: {epoch}, train mean accuracy: {train_acc: .3f}, test accuracy: {test_acc: .3f}')
    # æ‰€æœ‰epochsç»“æŸåï¼Œè¿›è¡Œç”»å›¾ï¼Œæ‰“å°æœ€åä¸€ä¸ªepochçš„è®­ç»ƒæŸå¤±ã€è®­ç»ƒç²¾åº¦ã€æµ‹è¯•ç²¾åº¦ã€æ€»çš„æ—¶é—´
    plot_training_curves(train_losses, train_accuracies, test_accuracies, num_epochs)
    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, 'f'test acc {test_acc:.3f}')
    # print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec 'f'on {str(device)}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec 'f'on {device}')


def try_gpu(i=0):
    if torch.cuda.device_count()>=i+1:
        # PyTorch çš„è®¾å¤‡å­—ç¬¦ä¸²æœ‰ä¸¥æ ¼çš„æ ¼å¼è¦æ±‚ï¼š
        # f'cuda:{i}'ï¼Œå†’å·åé¢æ²¡æœ‰ç©ºæ ¼ï¼Œæ­£ç¡®
        # f'cuda: {i}'ï¼Œå†’å·åé¢æ²¡æœ‰ç©ºæ ¼ï¼Œé”™è¯¯
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')

def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦æ‰§è¡Œçš„ä»£ç """
    print("ğŸš€ Section01.py çš„ä¸»å‡½æ•°")
    X = torch.randn(1, 1, 224, 224)
    for layer in net:
        X = layer(X)
        print(layer.__class__.__name__, 'output shape:\t', X.shape)
    batch_size = 64
    train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)
    lr, num_epochs = 0.01, 10
    train_ch7(net, train_iter, test_iter, num_epochs, lr, try_gpu())
# åªæœ‰ç›´æ¥è¿è¡Œæœ¬æ–‡ä»¶æ—¶æ‰æ‰§è¡Œmain()
if __name__ == '__main__':
    main()
