# -*- coding:utf-8 -*-
'''
ä½œè€…ï¼šcy
æ—¥æœŸï¼š2025å¹´11æœˆ06æ—¥
7.6 æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰

æ®‹å·®ç½‘ç»œçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šæ¯ä¸ªé™„åŠ å±‚éƒ½åº”è¯¥æ›´å®¹æ˜“åœ°åŒ…å«åŸå§‹å‡½æ•°ä½œä¸ºå…¶å…ƒç´ ä¹‹ä¸€ã€‚

å¯¹äºæ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¦‚æœæˆ‘ä»¬èƒ½å°†æ–°æ·»åŠ çš„å±‚è®­ç»ƒæˆæ’ç­‰æ˜ å°„ï¼ˆidentity functionï¼‰f(x) = xï¼Œ
æ–°æ¨¡å‹å’ŒåŸæ¨¡å‹å°†åŒæ ·æœ‰æ•ˆã€‚
'''

import Section01
import torch
from torch import nn
from torch.nn import functional as F

# 7.6.2 æ®‹å·®å—
class Residual(nn.Module):
    def __init__(self, input_channels, num_channels,use_1x1conv=False, strides=1):
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels,kernel_size=3, padding=1, stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels,kernel_size=3, padding=1)
        if use_1x1conv:
            # 1*1çš„å·ç§¯å±‚æ˜¯ä¸ºäº†å®ç°å°†è¾“å…¥ç›´æ¥åŠ åœ¨æœ€åçš„ReLUæ¿€æ´»å‡½æ•°å‰ï¼Œè¿™æ˜¯ResNetæ¨¡å‹çš„æ ¸å¿ƒ
            # å¼•å…¥ä¸€ä¸ªé¢å¤–çš„1 Ã— 1å·ç§¯å±‚æ¥å°†è¾“å…¥å˜æ¢æˆéœ€è¦çš„å½¢çŠ¶åå†åšç›¸åŠ è¿ç®—
            self.conv3 = nn.Conv2d(input_channels, num_channels,kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))   # å·ç§¯1-->è§„èŒƒåŒ–-->éçº¿æ€§æ¿€æ´»
        Y = self.bn2(self.conv2(Y))     # å·ç§¯2-->è§„èŒƒåŒ–
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)

# ResNetåˆ™ä½¿ç”¨4ä¸ªç”±æ®‹å·®å—ç»„æˆçš„æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨è‹¥å¹²ä¸ªåŒæ ·è¾“å‡ºé€šé“æ•°çš„æ®‹å·®å—ã€‚
def resnet_block(input_channels, num_channels, num_residuals,first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(input_channels, num_channels,use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels, num_channels))
    return blk


def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦æ‰§è¡Œçš„ä»£ç """
    print("ğŸš€ Section06.py çš„ä¸»å‡½æ•°")
    blk = Residual(3, 3)
    X = torch.rand(4, 3, 6, 6)
    Y = blk(X)
    print('Y.shape = ',Y.shape)
    blk = Residual(3, 6, use_1x1conv=True, strides=2)
    print('blk(X).shape = ',blk(X).shape)
    # 7.6.3 ResNetæ¨¡å‹
    # ResNetçš„å‰ä¸¤å±‚è·Ÿä¹‹å‰ä»‹ç»çš„GoogLeNetä¸­çš„ä¸€æ ·ï¼šåœ¨è¾“å‡ºé€šé“æ•°ä¸º64ã€æ­¥å¹…ä¸º2çš„7 Ã— 7å·ç§¯å±‚åï¼Œ
    # æ¥æ­¥å¹…ä¸º2çš„3 Ã— 3çš„æœ€å¤§æ±‡èšå±‚ã€‚ä¸åŒä¹‹å¤„åœ¨äºResNetæ¯ä¸ªå·ç§¯å±‚åå¢åŠ äº†æ‰¹é‡è§„èŒƒåŒ–å±‚ã€‚
    b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                       nn.BatchNorm2d(64), nn.ReLU(),
                       nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
    # æ¥ç€åœ¨ResNetåŠ å…¥æ‰€æœ‰æ®‹å·®å—ï¼Œè¿™é‡Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨2ä¸ªæ®‹å·®å—ã€‚
    b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))
    b3 = nn.Sequential(*resnet_block(64, 128, 2))
    b4 = nn.Sequential(*resnet_block(128, 256, 2))
    b5 = nn.Sequential(*resnet_block(256, 512, 2))
    # æ¯ä¸ªæ¨¡å—æœ‰4ä¸ªå·ç§¯å±‚ï¼ˆä¸åŒ…æ‹¬æ’ç­‰æ˜ å°„çš„1 Ã— 1å·ç§¯å±‚ï¼‰ã€‚
    # åŠ ä¸Šç¬¬ä¸€ä¸ª7 Ã— 7å·ç§¯å±‚å’Œæœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œ
    # å…±æœ‰18å±‚ã€‚å› æ­¤ï¼Œè¿™ç§æ¨¡å‹é€šå¸¸è¢«ç§°ä¸ºResNetâ€18ã€‚
    net = nn.Sequential(b1, b2, b3, b4, b5,
                        nn.AdaptiveAvgPool2d((1, 1)),
                        nn.Flatten(), nn.Linear(512, 10))
    X = torch.rand(size=(1, 1, 224, 224))
    for layer in net:
        X = layer(X)
        print(layer.__class__.__name__, 'output shape:\t', X.shape)
    lr, num_epochs, batch_size = 0.05, 10, 256
    train_iter, test_iter = Section01.load_data_fashion_mnist(batch_size, resize=96)
    Section01.train_ch7(net, train_iter, test_iter, num_epochs, lr, Section01.try_gpu())

if __name__ == '__main__':
    main()
